import numpy as np                      # Biblioteca para opera√ß√µes com arrays
import tensorflow as tf                 # Biblioteca principal de deep learning (Framework)
from tensorflow import keras            # API de alto n√≠vel do TensorFlow para redes neurais
from tensorflow.keras import layers     # Camadas (Layers) do Keras, para constru√ß√£o de modelos 


(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()   # Carrega imagens de treino e teste do MNIST (imagens 28x28 escalas de cinza)
x_train = x_train.astype("float32") / 255.                     # Normaliza os pixels de 0-255 para 0-1 (facilita os calculos da rede)
x_train = np.expand_dims(x_train, -1)                          # Adiciona dimens√£o do canal pois a rede espera um entradas 4D (fica [N, 28, 28, 1] ou [batch, x, y, 1]) 
x_test = x_test.astype("float32") / 255.                       # Normaliza os pixels de 0-255 para 0-1 (facilita os calculos da rede)
x_test = np.expand_dims(x_test, -1)                            # Adiciona dimens√£o do canal pois a rede espera um entradas 4D (fica [N, 28, 28, 1] ou [batch, x, y, 1])



latent_dim = 16    # Dimens√£o do espa√ßo latente
batch_size = 128   # Tamanho do lote
epochs = 50        # N√∫mero de √©pocas de treinamento


# Encoder -------------------------------------------------------------------------------------------------------------------------------------------------------------
encoder_inputs = keras.Input(shape=(28, 28, 1))        # Define entrada do Encoder Convolucional (fica [28x28x1] ou [x,y,channel])

x = layers.Conv2D(
    32,                                # 32 filtros                                           # 1¬™ Camada Convolucional
    3,                                 # Kernel 3x3                                           # 1¬™ Camada Convolucional
    activation="relu",                 # Fun√ß√£o de ativa√ß√£o ReLU                              # 1¬™ Camada Convolucional
    strides=2,                         # Passo (Passo 2 reduz dimens√£o pela metade)           # 1¬™ Camada Convolucional
    padding="same"                     # Matem as dimens√µes definida pelo stride              # 1¬™ Camada Convolucional
    )(encoder_inputs)                  # Vari√°vel de entrada da camada                        # 1¬™ Camada Convolucional

x = layers.Conv2D(
    64,                                # 32 filtros                                           # 2¬™ Camada Convolucional
    3,                                 # Kernel 3x3                                           # 2¬™ Camada Convolucional
    activation="relu",                 # Fun√ß√£o de ativa√ß√£o ReLU                              # 2¬™ Camada Convolucional
    strides=2,                         # Passo (Passo 2 reduz dimens√£o pela metade)           # 2¬™ Camada Convolucional
    padding="same"                     # Matem as dimens√µes definida pelo stride              # 2¬™ Camada Convolucional
    )(x)                               # variavel de entrada da camada                        # 2¬™ Camada Convolucional

x = layers.Flatten()(x)                # "Achata" a sa√≠da do layer em um vetor 1D para conectar na camada densa

x = layers.Dense(
    128,                               # Camada densa (fully conected) 128 neuros             # Camada densa intermedi√°ria
    activation="relu"                  # Fun√ß√£o de ativa√ß√£o ReLU                              # Camada densa intermedi√°ria
    )(x)                               # Vari√°vel de entrada da camada                        # Camada densa intermedi√°ria

z_mean = layers.Dense(
    latent_dim,                    # Sa√≠da da camada na dimens√£o latente                  # Sa√≠da: m√©dia das posi√ß√µes no espa√ßo latente
    name="z_mean"                  # Nome da sa√≠da                                        # Sa√≠da: m√©dia das posi√ß√µes no espa√ßo latente
    )(x)                           # Vari√°vel de entrada da camada                        # Sa√≠da: m√©dia das posi√ß√µes no espa√ßo latente

z_log_var = layers.Dense(
    latent_dim,                # Sa√≠da da camada na dimens√£o latente                  # Sa√≠da: log da vari√¢ncia no espa√ßo latente
    name="z_log_var"           # Nome da camada                                       # Sa√≠da: log da vari√¢ncia no espa√ßo latente
    )(x)                       # Vari√°vel de entrada da camada                        # Sa√≠da: log da vari√¢ncia no espa√ßo latente

@keras.utils.register_keras_serializable()             # Permite salvar/carregar a fun√ß√£o customizada junto ao keras 

def sampling(args):                                                                                           # Reparametrization Trick 
    z_mean, z_log_var = args                           # Importa m√©dia e log vari√¢ncia                        # Reparametrization Trick
    batch = tf.shape(z_mean)[0]                        # Extrai tamanho lote (batch)                          # Reparametrization Trick
    dim = tf.shape(z_mean)[1]                          # Extrai dimens√£o espa√ßo latente                       # Reparametrization Trick 
    epsilon = tf.random.normal(shape=(batch, dim))     # Gera ru√≠do aleat√≥rio ‚àà por batch                     # Reparametrization Trick
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon  # retorna z = ùùÅ + ùùà ‚ãÖ ‚àà                                # Reparametrization Trick

z = layers.Lambda(
    sampling,                          # Fun√ß√£o "sampling" retorna z de forma diferenciavel   # Reparametrization Trick
    output_shape=(latent_dim,),        # Informa ao keras o formato de sa√≠da da fun√ß√£o        # Reparametrization Trick
    name="z"                           # Nome da camada                                       # Reparametrization Trick
    )([z_mean, z_log_var])             # Informa ao keras entrada da fun√ß√£o                   # Reparametrization Trick


encoder = keras.Model(
    encoder_inputs,               # Cria modelo do encoder e define variavel de entrada
    [z_mean,                       # Retorna m√©dia
    z_log_var,                     # Retorna Log da vari√¢ncia 
    z],                            # Retorna vetor z amostrado
    name="encoder")                # Nomeia o encoder

# Encoder ------------------------------------------------------------------------------------------------------------------------------------------------------------------

# Decoder ------------------------------------------------------------------------------------------------------------------------------------------------------------------

latent_inputs = keras.Input(shape=(latent_dim,))                    # Define entrada do Decoder Convolucional (vetor latente)

x = layers.Dense   (7 * 7 * 64,                                     # Cada vetor latente ser√° tranformado em 3136 valores
                    activation="relu"                               # Fun√ß√£o de ativa√ß√£o ReLU
                    )(latent_inputs)                                # Vari√°vel de entrada da camada

x = layers.Reshape ((7, 7, 64)                                      # Reorganiza os 3136 valores em um tensor 3D [7, 7, 64]
                    )(x)                                            # Vari√°vel de entrada da camada

x = layers.Conv2DTranspose(64,                                      # 64 filtros                                       # 1¬™ Camada Deconvolucional
                            3,                                      # Kernel 3x3                                       # 1¬™ Camada Deconvolucional
                            activation="relu",                      # Fun√ß√£o de ativa√ß√£o ReLU                          # 1¬™ Camada Deconvolucional
                            strides=2,                              # Passo (Passo 2 dobra a dimens√£o)                 # 1¬™ Camada Deconvolucional
                            padding="same"                          # Matem as dimens√µes definida pelo stride          # 1¬™ Camada Deconvolucional
                            )(x)                                    # variavel de entrada da camada                    # 1¬™ Camada Deconvolucional

x = layers.Conv2DTranspose(32,                                      # 32 filtros                                       # 2¬™ Camada Deconvolucional
                            3,                                      # Kernel 3x3                                       # 2¬™ Camada Deconvolucional
                            activation="relu",                      # Fun√ß√£o de ativa√ß√£o ReLU                          # 2¬™ Camada Deconvolucional
                            strides=2,                              # Passo (Passo 2 dobra a dimens√£o)                 # 2¬™ Camada Deconvolucional
                            padding="same"                          # Matem as dimens√µes definida pelo stride          # 2¬™ Camada Deconvolucional
                            )(x)                                    # variavel de entrada da camada                    # 2¬™ Camada Deconvolucional              

decoder_outputs = layers.Conv2DTranspose   (1,                      # 1 filtro                                         # Camada Deconvolucional de sa√≠da
                                            3,                      # Kernel 3x3                                       # Camada Deconvolucional de sa√≠da
                                            activation="sigmoid",   # Fun√ß√£o de ativa√ß√£o                               # Camada Deconvolucional de sa√≠da
                                            strides=1,              # Passo                                            # Camada Deconvolucional de sa√≠da
                                            padding="same"          # Matem a dimens√£o igual a entrada se stride = 1   # Camada Deconvolucional de sa√≠da
                                            )(x)                    # variavel de entrada da camada                    # Camada Deconvolucional de sa√≠da

decoder = keras.Model  (latent_inputs,                              # Cria modelo do decoder e define variavel de entrada
                        decoder_outputs,                            # Define variavel da imagem reconstruida
                        name="decoder")                             # Nomeia o decoder
# Decoder --------------------------------------------------------------------------------------------------------------------------------------------------------------




class VAE(keras.Model):   # Cria subclasse do modelo VAE para customiza√ß√£o no keras

    def __init__(self, encoder, decoder, **kwargs):    # Construtor da classe, define seus argumentos  - **kwargs permite inviar mais argumentos alem dos obrigat√≥rios
        super().__init__(**kwargs)                     # Chama o construtor da subclasse (obrigat√≥rio) - **kwargs permite inviar mais argumentos alem dos obrigat√≥rios
        self.encoder = encoder                         # Salva encoder como atributo de objeto 
        self.decoder = decoder                         # Salva decoder como atributo de objeto

    def call(self, inputs):                            # Define oque acontece quando chamamos a classe VAE()            # Forward pass
        z_mean, z_log_var, z = self.encoder(inputs)    # Define a entrada e as sa√≠das do encoder                        # Forward pass
        return self.decoder(z)                         # detorna o decoder(z) que √© a imagem reconstru√≠da               # Forward pass

    def train_step(self, data):                        # Passo de treinamento customizado
        if isinstance(data, tuple):                    # Ignora os r√≥tulos do das imagens do dataset se houver
            data = data[0]                             # Ignora os r√≥tulos do das imagens do dataset se houver

        with tf.GradientTape() as tape:                # Abre o escopo para registar as opera√ß√µes 0     
            z_mean, z_log_var, z = self.encoder(data)  # A entrada passa pelo encoder retornado as variaveis no espa√ßo latente         # Forward pass
            reconstruction = self.decoder(z)           # As variaveis no espa√ßo latente passam pelo encoder e reconstroem a imagem     # Forward pass

            reconstruction_loss = tf.reduce_mean(                                    # Faz a m√©dia sobre todas as imagens do batch
                                                tf.reduce_sum(                       # Soma a entropia cruzada sobre as dimens√µes espaciais (28x28)
                                                keras.losses.binary_crossentropy(    # Aplica a fun√ß√£o de entropia cruzada
                                                data,                                # Imagem de entrada
                                                reconstruction),                     # Imagem reconstru√≠da
                                                axis=(1, 2)))                        # Soma a entropia cruzada sobre as dimens√µes espaciais (28x28)
            
#            reconstruction_loss = tf.reduce_mean(                                   # Faz a m√©dia sobre todas as imagens do batch                                
#                                                tf.sqrt(                            # Aplica a raiz quadrada
#                                                tf.reduce_mean(                     # Faz a m√©dia dos erros ao quadrado por imagem
#                                                tf.square(                          # Eleva as diferen√ßas ao quadrado
#                                                data - reconstruction),             # Cria tensor de erros (diferen√ßas)
#                                                axis=(1, 2, 3))))                   # Faz a m√©dia dos erros ao quadrado por imagem (Altura, Largura, Canal)

            kl_loss = -0.5 * tf.reduce_mean(                                                         # Faz a m√©dia sobre todas as imagens do batch 
                                            tf.reduce_sum(                                           # Soma os termos de cada dimens√£o latente
                                            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var),   # 1 + log(œÉ¬≤‚Äã)‚àíŒº¬≤‚Äã‚àíœÉ¬≤‚Äã       
                                            axis=1))                                                 # Soma os termos de cada dimens√£o latente
            
            total_loss = reconstruction_loss + kl_loss                                               # Soma as perdas

        grads = tape.gradient(           # Calcula os gradientes da fun√ß√£o de perda       # Backpropagation
                total_loss,              # Entre a fun√ß√£o de perda                        # Backpropagation
                self.trainable_weights)  # E os pesos de treinamento                      # Backpropagation
        
        self.optimizer.apply_gradients(                 # Otimizador do modelo "adam"                           # Wnovo = Wantigo ‚àí Œ∑ ‚ãÖ ‚àáw loss
                zip(grads, self.trainable_weights))     # Combina o gradiente com seu respectivo peso           # W = peso 
                                                                                                                # Œ∑ = taxa de aprendizado (depende do modelo)
                                                                                                                # ‚àáw loss = gradiente da perda em rela√ß√£ao a W 
        
        return {"loss": total_loss, "reconstruction_loss": reconstruction_loss, "kl_loss": kl_loss}             # Retorna m√©tricas


def dummy_loss(y_true, y_pred): return 0.0    # Fun√ß√£o de loss dummy (necess√°ria para o compile)
    
vae = VAE(encoder, decoder)                     # Inicia s subclasse VAE
vae.compile(optimizer="adam",   # Define o modelo de otimizador "adam" 
            loss=dummy_loss)    # Fun√ßao loss j√° √© aplicada no train, sem fun√ßao aqui

vae.fit(                                 # Inicia treinamento do modelo
    x_train,                             # Dataset de treinamento
    epochs = epochs,                     # N√∫mero de treinamentos
    batch_size = batch_size,             # Lotes por treinamento
    validation_data=(x_test, x_test))    # Valida√ß√£o (passa pelo mesmo processo sem atualiza√ß√£o de pesos para valida√ß√£o) 

encoder.save("CVAE_encoder_train.h5")  # Salva encoder treinado
decoder.save("CVAE_decoder_train.h5")  # Salva decoder treinado
